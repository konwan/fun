{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/Soft_Job/M.1523181507.A.EF8.html' target='_blank' >Soft_Job 4/08 [徵才] 台北新創WeiFu 徵UI/前、後端工程師</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/Soft_Job/M.1523248224.A.C77.html' target='_blank' >Soft_Job 4/09 [徵才] 壯生醫材：資訊相關短期兼職</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/Soft_Job/M.1523271347.A.316.html' target='_blank' >Soft_Job 4/09 [徵才]Oriente誠徵Lead Backend Engineer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/Soft_Job/M.1523271442.A.653.html' target='_blank' >Soft_Job 4/09 [徵才]Oriente 誠徵Lead QA Automation Engineer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/Soft_Job/M.1523279926.A.124.html' target='_blank' >Soft_Job 4/09 [徵才] 創業團隊技術主管</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/Soft_Job/M.1501827692.A.18D.html' target='_blank' >Soft_Job 8/04 [公告] 徵才不符板規或徵才自刪公司</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/Tech_Job/M.1523262920.A.A40.html' target='_blank' >Tech_Job 4/09 [徵才] 台大新創團隊誠徵業務開發</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/WorkinChina/M.1523154795.A.EE5.html' target='_blank' >WorkinChina 4/08 [求才] Nanigans 北京市場行銷經理</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/Oversea_Job/M.1523155680.A.350.html' target='_blank' >Oversea_Job 4/08 [亞洲徵才] Nanigans 新加坡客戶經理</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/job/M.1523262063.A.14F.html' target='_blank' >Job 4/09 [台北] Positive Grid 徵 HR Admin(具財會背景)</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://www.ptt.cc/bbs/job/M.1523298392.A.229.html' target='_blank' >Job 4/10 [北部] C Park By A Train餐酒館徵才</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.support.select import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from IPython.core.display import display, HTML\n",
    "from datetime import datetime\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Ptt(object):\n",
    "    fp = \"/Users/cindy/Desktop/pg/mit/fun\"\n",
    "    dp = \"/Users/cindy/Desktop/pg/driver/chromedriver\"\n",
    "    dm = \"https://www.ptt.cc\"\n",
    "    \n",
    "    def __init__(self, board, updatedate, pages): \n",
    "        self.lastdt = ( date.today() - timedelta(updatedate))#.strftime(\"%m/%d\").lstrip(\"0\")\n",
    "        self.brd = board\n",
    "        self.lastidx = 0\n",
    "        self.data = []\n",
    "        self.page_num = pages\n",
    "        self.webres = None\n",
    "\n",
    "        \n",
    "    def start(self):    \n",
    "        self.driver = webdriver.Chrome(self.dp)\n",
    "        self.url = \"{}/bbs/{}/index{}.html\".format(self.dm, self.brd, self.lastidx)\n",
    "       \n",
    "    def end(self):\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "    \n",
    "    def getIndex(self):\n",
    "        self.driver.get(self.url)\n",
    "        self.webres = BeautifulSoup(self.driver.page_source, \"lxml\")\n",
    "        # over 18 check\n",
    "        btns18 = self.webres.find_all(\"div\", class_ = \"over18-button-container\")\n",
    "        if len(btns18) != 0:\n",
    "            self.driver.find_element_by_name(\"yes\").click()\n",
    "            self.webres = BeautifulSoup(self.driver.page_source, \"lxml\")\n",
    "        self.lastidx =  1 + int(self.webres.find_all(\"a\", class_ = \"btn wide\")[1][\"href\"].replace(\"index\",\"\").replace(\".html\",\"\").split(\"/\")[3])   \n",
    " \n",
    "    def getposts(self):\n",
    "        self.start()\n",
    "        self.getIndex() \n",
    "        \n",
    "        for i in range(self.lastidx-self.page_num+1, self.lastidx+1): \n",
    "            self.url = \"{}/bbs/{}/index{}.html\".format(self.dm, self.brd, i)  \n",
    "            self.driver.get(self.url)\n",
    "            self.webres = BeautifulSoup(self.driver.page_source, \"lxml\")\n",
    "            \n",
    "            # over 18 check\n",
    "            btns18 = self.webres.find_all(\"div\", class_ = \"over18-button-container\")\n",
    "            if len(btns18) != 0:\n",
    "                self.driver.find_element_by_name(\"yes\").click()\n",
    "                self.webres = BeautifulSoup(self.driver.page_source, \"lxml\")\n",
    "            \n",
    "            posts = self.webres.find_all(\"div\", class_ = \"r-ent\")\n",
    "            for p in posts:\n",
    "                title = p.find(\"div\", class_=\"title\").getText().strip() \n",
    "                if title is not None:\n",
    "                    dt = p.find(\"div\", class_ = \"date\").text.strip() \n",
    "                    ardt = datetime.strptime(\"2018/{}\".format(dt), \"%Y/%m/%d\").date()\n",
    "\n",
    "                    if self.lastdt <= ardt:\n",
    "                        keywords = [\"徵才\",\"徵\",\"找人\",\"求才\",\"找\",\"求\"]\n",
    "                        words = [j for j in jieba.cut_for_search(re.sub('[\\W\\d_]+', ' ', title)) if j in keywords]\n",
    "                        if len(words) > 0 :          \n",
    "                            url = p.find(\"a\")[\"href\"]\n",
    "                            athr = p.find(\"div\", class_ = \"author\").getText()\n",
    "                            tmpcmt = p.find(\"div\", class_ = \"nrec\").text\n",
    "                            cmt = int(tmpcmt) if tmpcmt.isdigit() else np.nan\n",
    "                            self.data.append([self.brd, dt, cmt, title, url])\n",
    "                            display(HTML(\"<a href='{}{}' target='_blank' >{} {} {}</a>\".format(self.dm, url, self.brd, dt, title))) \n",
    "        self.end()\n",
    "\n",
    "jobs = [\"Soft_Job\", \"Tech_Job\",\"WorkinChina\",\"Oversea_Job\",\"Job\",\"TaiwanJobs\"]\n",
    "alljob = []\n",
    "for i in jobs:\n",
    "    p = Ptt(i, 2, 3)\n",
    "    p.getposts()\n",
    "    alljob.append(p.data)\n",
    "from functools import reduce\n",
    "alljob = reduce(lambda x,y: x+y, alljob)\n",
    "\n",
    "col = ['brd','date','cmt','title','url']\n",
    "result = pd.DataFrame(alljob, columns=col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cnt\n",
      "台北   12\n",
      "助理    8\n",
      "徵才    7\n",
      "研究    6\n",
      "行政    5\n",
      "客服    4\n",
      "公司    4\n",
      "師     4\n",
      "外商    3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "stopwords = ['Re','DELETE',' ', '沒', '才', '第', '的', '次', '了', '和', '是', '就', '都', '而', '及', '與', '一個', '沒有', '我們', '你們', '妳們', '他們', '她們', '是否', '一', '不', '在', '人', '有', '為', '以', '於', '上', '他', '後', '之', '來', '因', '下', '可', '到', '由', '這', '也', '此', '但', '並', '個', '其', '已', '無', '小', '我', '們', '起', '最', '再', '今', '去', '好', '只', '又', '或', '很', '亦', '某', '把', '那', '你', '乃', '它', '吧', '被', '比', '別', '趁', '當', '從', '到', '得', '打', '凡', '兒', '爾', '該', '各', '給', '跟', '何', '還', '即', '幾', '既', '看', '據', '距', '靠', '啦', '了', '另', '麼', '每', '們', '嘛', '拿', '哪', '那', '您', '憑', '且', '卻', '讓', '仍', '啥', '如', '若', '使', '誰', '雖', '隨', '同', '所', '她', '哇', '嗡', '往', '哪', '些', '向', '沿', '喲', '用', '於', '咱', '則', '怎', '曾', '至', '致', '著', '諸', '自']\n",
    "words = [j for i in result['title'] for j in jieba.cut_for_search(re.sub('[\\W\\d_]+', ' ', i)) if j not in stopwords]\n",
    "wdf = pd.DataFrame(words, columns=['word'])\n",
    "r = wdf['word'].value_counts().to_frame(name='cnt')\n",
    "print(r[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前正在爬取 137698833067234 資料視覺化 / Data Visualization 第1頁\n",
      "目前正在爬取 1703467299932229 Data Man 的資料視覺化筆記 第1頁\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from dateutil.parser import parse\n",
    "\n",
    "\n",
    "# 在Facebook Graph API Exploer取得token\n",
    "\n",
    "token = 'EAACEdEose0cBAFuvuZAX3ZBP2KyZBHxXpU3athgfffKLkbebFJDXciLlSHNXhbwbCZBFwBITpE6iFw5MEhzRMpOZAb1HUfOTByZB6l0s7ELTZCB5RlwiloPWaA6WzhRBVYFXyZC3osB1fu5XqyLo3tUy1rnuIZC3f4wUGoZAh1oYMDS6N0HIWne75NAZBDJaZCVLIgySKHA5WMlgPdVuzGeozuF2hGZBIVL2qYx4lrUDqx0tSawZDZD'\n",
    "# 在Facebook Graph API Exploer取得粉絲專頁的id與名稱，並將其包成字典dic\n",
    "\n",
    "fanpages = {'137698833067234':'資料視覺化 / Data Visualization',\n",
    "           '1703467299932229':'Data Man 的資料視覺化筆記'} \n",
    "limit = 1\n",
    "# 建立一個空的list        \n",
    "\n",
    "information_list = []\n",
    "\n",
    "# 使用for迴圈依序讀取粉絲頁的資訊，並使用format將id與token傳入{}裡\n",
    "\n",
    "for fanpage_id in fanpages:\n",
    "    res = requests.get('https://graph.facebook.com/v2.12/{}/posts?limit=100&access_token={}'.format(fanpage_id, token))\n",
    "\n",
    "    # API最多一次呼叫100筆資料，因此使用while迴圈去翻頁取得所有的資料\n",
    "\n",
    "    pages = 1  # 初始化爬取頁數 \n",
    "    while True: \n",
    "        if pages <= limit :\n",
    "            print('目前正在爬取 {} {} 第{}頁'.format(fanpage_id, fanpages[fanpage_id], pages))\n",
    "            for information in res.json()['data']:\n",
    "                if 'message' in information:\n",
    "                    information_list.append([fanpages[fanpage_id], information['message'], parse(information['created_time']).date()])\n",
    "\n",
    "            # 若有下一頁，則繼續爬取，否則跳出While迴圈\n",
    "\n",
    "            if 'next' in res.json()['paging']:\n",
    "                res = requests.get(res.json()['paging']['next'])\n",
    "                pages += 1\n",
    "            else:\n",
    "                print('{} {} 已爬取完成! \\n'.format(fanpage_id, fanpages[fanpage_id]))\n",
    "                break\n",
    "        else :\n",
    "            break\n",
    "\n",
    "# 最後將list轉換成dataframe，並輸出成Excel檔\n",
    "# information_df = pd.DataFrame(information_list, columns=['粉絲專頁', '發文內容', '發文時間']) \n",
    "# print(information_df[0:3])\n",
    "# information_df.to_excel('Data Visualization Information.xlsx', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
